# Story 3.2: Model Translation and Metadata Enhancement

## Status
Approved

## Story
**As a** developer using Ollama SDK,
**I want** OpenAI models properly translated with all expected Ollama metadata,
**so that** my application can display and use model information correctly

## Acceptance Criteria

1. Translation logic handles all OpenAI model types (GPT, text-embedding, etc.)
2. Model names are mapped to Ollama-compatible format
3. Dummy metadata is realistic and consistent for each model type
4. Size calculations are based on reasonable estimates for model parameters
5. Digest/hash values are generated consistently for the same model
6. Model families are properly identified and grouped
7. Parameter counts and quantization info follow Ollama conventions
8. All edge cases are handled (unknown models, missing fields, etc.)

## Tasks / Subtasks

- [ ] Define Ollama model response structure (AC: 1, 2)
  - [ ] Create/update Pydantic models in `app/models/ollama/models.py`
  - [ ] Define TagsResponse model matching Ollama SDK expectations
  - [ ] Define ModelInfo model with all required fields
  - [ ] Add validation rules for required fields

- [ ] Implement model name mapping (AC: 2)
  - [ ] Create mapping dictionary in `app/translators/mappings.py`
  - [ ] Map OpenAI model IDs to Ollama-style names (e.g., "gpt-3.5-turbo" â†’ "gpt3.5")
  - [ ] Handle versioned models appropriately
  - [ ] Implement fallback for unknown models

- [ ] Generate realistic metadata (AC: 3, 4, 7)
  - [ ] Create metadata generation functions in translation layer
  - [ ] Estimate model sizes based on known parameters
  - [ ] Generate consistent digest/hash values using model ID
  - [ ] Add quantization info (e.g., "Q4_0", "F16") based on model type
  - [ ] Include parameter counts for known models

- [ ] Implement model family grouping (AC: 6)
  - [ ] Identify model families (GPT, Embedding, etc.)
  - [ ] Add family information to model details
  - [ ] Group related models in response

- [ ] Handle edge cases (AC: 8)
  - [ ] Add validation for missing OpenAI fields
  - [ ] Provide sensible defaults for unknown models
  - [ ] Log warnings for unmapped models
  - [ ] Ensure response is always valid Ollama format

- [ ] Create comprehensive unit tests
  - [ ] Test translation with various OpenAI model responses
  - [ ] Test edge cases (null fields, unknown models)
  - [ ] Test metadata generation consistency
  - [ ] Test model name mapping
  - [ ] Verify Pydantic validation works correctly

- [ ] Update integration tests
  - [ ] Add test cases for different model types
  - [ ] Verify Ollama SDK can parse all model variations
  - [ ] Test with actual OpenAI model list from references

## Dev Notes

### Ollama Model Format
[Source: From SDK types extraction in references/ollama-types/models.py]
Expected Ollama tags response structure:
```python
{
    "models": [
        {
            "name": "llama2:7b",
            "modified_at": "2023-08-02T17:02:23.713454393-07:00",
            "size": 3825819519,
            "digest": "78e26419b4469263f75331927a00a0284ef6544c1975b826b15abdaef17bb962",
            "details": {
                "format": "gguf",
                "family": "llama",
                "families": ["llama"],
                "parameter_size": "7B",
                "quantization_level": "Q4_0"
            }
        }
    ]
}
```

### OpenAI Model Format
[Source: references/openai-examples/models.json]
OpenAI returns:
```python
{
    "id": "gpt-3.5-turbo",
    "object": "model",
    "created": 1677610602,
    "owned_by": "openai"
}
```

### Model Mapping Strategy
[Source: architecture/data-models.md#Model-Mapping]
- Use parameter_map for direct field mappings
- Log warnings for unsupported_params
- Apply value_transformers for format conversions

### Known Model Parameters
Common models and their approximate sizes:
- gpt-3.5-turbo: ~20B parameters
- gpt-4: ~175B parameters  
- text-embedding-ada-002: ~300M parameters

### Metadata Generation Rules
1. Size: Calculate based on parameter count (rough estimate: 4 bytes per parameter)
2. Digest: Use consistent hash of model ID (SHA256)
3. Modified date: Use model creation timestamp from OpenAI
4. Format: Default to "gguf" for all models
5. Quantization: Use "F16" for smaller models, "Q4_0" for larger

### Testing Standards
[Source: architecture/test-strategy-and-standards.md]
- Create comprehensive unit tests in `tests/unit/test_model_translation.py`
- Test all mapping scenarios and edge cases
- Verify consistent metadata generation
- Use fixtures from `references/openai-examples/models.json`

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-07-31 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
<!-- To be filled by dev agent -->

### Debug Log References
<!-- To be filled by dev agent -->

### Completion Notes List
<!-- To be filled by dev agent -->

### File List
<!-- To be filled by dev agent -->

## QA Results
<!-- To be filled by QA agent -->